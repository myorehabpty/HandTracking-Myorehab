{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97c4453",
   "metadata": {},
   "source": [
    "CREATE DIR STRUCTURE FOR ANIPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f987a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe3261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose project name and working directory\n",
    "new_project_directory = r'C:/Users/myore/Desktop/MYOREHAB'\n",
    "new_project_name = 'HandTracking'\n",
    "\n",
    "# get list of new sessions\n",
    "sessionlist = [\n",
    "    'session1',\n",
    "    'session2',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2564048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! New Anipose Project created: C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\n"
     ]
    }
   ],
   "source": [
    "# create project structure\n",
    "for session in sessionlist:\n",
    "    # make videos-raw folder for behavior\n",
    "    videopath = os.path.join(new_project_directory, new_project_name, session, 'videos-raw')\n",
    "    os.makedirs(videopath)\n",
    "\n",
    "    # make calibration folder\n",
    "    calibrationpath = os.path.join(new_project_directory, new_project_name, session, 'calibration')\n",
    "    os.makedirs(calibrationpath)\n",
    "\n",
    "# save project directory\n",
    "projectpath = os.path.join(new_project_directory, new_project_name)\n",
    "os.chdir(projectpath)\n",
    "\n",
    "print(f'Done! New Anipose Project created: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20abf87",
   "metadata": {},
   "source": [
    "CREATE config.toml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d872812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_extension = \"mp4\"\n",
      "converted_video_speed = 1\n",
      "\n",
      "[calibration]\n",
      "animal_calibration = false\n",
      "fisheye = false\n",
      "\n",
      "[manual_verification]\n",
      "manually_verify = false\n",
      "\n",
      "[triangulation]\n",
      "ransac = false\n",
      "optim = false\n",
      "scale_smooth = 2\n",
      "scale_length = 2\n",
      "scale_length_weak = 1\n",
      "reproj_error_threshold = 5\n",
      "score_threshold = 0.8\n",
      "n_deriv_smooth = 3\n",
      "constraints = []\n",
      "constraints_weak = []\n",
      "\n",
      "[pipeline]\n",
      "videos_raw = \"videos-raw\"\n",
      "videos_raw_mp4 = \"videos-raw-mp4\"\n",
      "pose_2d = \"pose-2d\"\n",
      "pose_2d_filter = \"pose-2d-filtered\"\n",
      "pose_2d_projected = \"pose-2d-proj\"\n",
      "pose_3d = \"pose-3d\"\n",
      "pose_3d_filter = \"pose-3d-filtered\"\n",
      "videos_labeled_2d = \"videos-labeled\"\n",
      "videos_labeled_2d_filter = \"videos-labeled-filtered\"\n",
      "calibration_videos = \"calibration\"\n",
      "calibration_results = \"calibration\"\n",
      "videos_labeled_3d = \"videos-3d\"\n",
      "videos_labeled_3d_filter = \"videos-3d-filtered\"\n",
      "angles = \"angles\"\n",
      "summaries = \"summaries\"\n",
      "videos_combined = \"videos-combined\"\n",
      "videos_compare = \"videos-compare\"\n",
      "videos_2d_projected = \"videos-2d-proj\"\n",
      "\n",
      "[filter]\n",
      "enabled = false\n",
      "type = \"medfilt\"\n",
      "medfilt = 13\n",
      "offset_threshold = 25\n",
      "score_threshold = 0.05\n",
      "spline = true\n",
      "n_back = 5\n",
      "multiprocessing = false\n",
      "\n",
      "[filter3d]\n",
      "enabled = false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default from anipos: https://github.com/lambdaloop/anipose/blob/master/anipose/anipose.py\n",
    "DEFAULT_CONFIG = {\n",
    "    'video_extension': 'mp4',\n",
    "    'converted_video_speed': 1,\n",
    "    'calibration': {\n",
    "        'animal_calibration': False,\n",
    "        'calibration_init': None,\n",
    "        'fisheye': False\n",
    "    },\n",
    "    'manual_verification': {\n",
    "        'manually_verify': False\n",
    "    },\n",
    "    'triangulation': {\n",
    "        'ransac': False,\n",
    "        'optim': False,\n",
    "        'scale_smooth': 2,\n",
    "        'scale_length': 2,\n",
    "        'scale_length_weak': 1,\n",
    "        'reproj_error_threshold': 5,\n",
    "        'score_threshold': 0.8,\n",
    "        'n_deriv_smooth': 3,\n",
    "        'constraints': [],\n",
    "        'constraints_weak': []\n",
    "    },\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'videos_raw_mp4': 'videos-raw-mp4',\n",
    "        'pose_2d': 'pose-2d',\n",
    "        'pose_2d_filter': 'pose-2d-filtered',\n",
    "        'pose_2d_projected': 'pose-2d-proj',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        'videos_labeled_2d': 'videos-labeled',\n",
    "        'videos_labeled_2d_filter': 'videos-labeled-filtered',\n",
    "        'calibration_videos': 'calibration',\n",
    "        'calibration_results': 'calibration',\n",
    "        'videos_labeled_3d': 'videos-3d',\n",
    "        'videos_labeled_3d_filter': 'videos-3d-filtered',\n",
    "        'angles': 'angles',\n",
    "        'summaries': 'summaries',\n",
    "        'videos_combined': 'videos-combined',\n",
    "        'videos_compare': 'videos-compare',\n",
    "        'videos_2d_projected': 'videos-2d-proj',\n",
    "    },\n",
    "    'filter': {\n",
    "        'enabled': False,\n",
    "        'type': 'medfilt',\n",
    "        'medfilt': 13,\n",
    "        'offset_threshold': 25,\n",
    "        'score_threshold': 0.05,\n",
    "        'spline': True,\n",
    "        'n_back': 5,\n",
    "        'multiprocessing': False\n",
    "    },\n",
    "    'filter3d': {\n",
    "        'enabled': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# create config.toml file\n",
    "configfile = os.path.join(projectpath, 'config.toml')\n",
    "\n",
    "with open(configfile, 'w') as f:\n",
    "     new_toml_string = toml.dump(DEFAULT_CONFIG, f)\n",
    "print(new_toml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21faaeeb",
   "metadata": {},
   "source": [
    "MOVE VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories with video data \n",
    "calibration_path = r'E:\\StopSignalSkinnerbox_local\\calibration'\n",
    "behavior_path = r'E:\\StopSignalSkinnerbox_local\\concatenated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate new project\n",
    "copy = False # copy or move\n",
    "list_of_sessions = os.listdir(projectpath)\n",
    "calibration_videos = os.listdir(calibration_path)\n",
    "behavior_videos = os.listdir(behavior_path)\n",
    "\n",
    "\n",
    "for session in list_of_sessions:\n",
    "    # check if directories are populated\n",
    "    session_dirs = os.listdir(os.path.join(projectpath, session))\n",
    "    \n",
    "    # subset relevant videos \n",
    "    date = session[0:10] #YYYY_MM_DD_(conditions!!)_P007_camR/L.mp4 #session naming convention: 2022_04_25_P403\n",
    "    id = session[11:]\n",
    "    videos_to_move = []\n",
    "    videos_moved = []\n",
    "    session_calibration_videos = [video for video in calibration_videos if id in video if date in video]\n",
    "    session_behavior_videos = [video for video in behavior_videos if id in video if date in video]\n",
    "\n",
    "    for dir in session_dirs:\n",
    "        done = os.listdir(os.path.join(projectpath, session, dir))\n",
    "        \n",
    "        # find videos for\n",
    "        if dir == 'calibration':\n",
    "            videos_to_move.extend([os.path.join(calibration_path,video) for video in session_calibration_videos if video not in done])\n",
    "            videos_moved.extend([os.path.join(projectpath, session, dir, video) for video in session_calibration_videos if video not in done])        \n",
    "        else:\n",
    "            videos_to_move.extend([os.path.join(behavior_path, video) for video in session_behavior_videos if video not in done])\n",
    "            videos_moved.extend([os.path.join(projectpath, session, dir, video) for video in session_behavior_videos if video not in done])  \n",
    "\n",
    "    # move or copy\n",
    "    print(f'Moving {len(videos_to_move)} videos for session {session}:')\n",
    "\n",
    "    if copy:\n",
    "        for video1, video2 in zip(videos_to_move, videos_moved):\n",
    "            copy_command = f'copy {video1} {video2}'\n",
    "            os.system(copy_command)\n",
    "            print(f'{video2} coped!')\n",
    "    else:\n",
    "        for video1, video2 in zip(videos_to_move, videos_moved):\n",
    "            os.rename(video1, video2)\n",
    "            print(f'{video2} moved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedcedb",
   "metadata": {},
   "source": [
    "UPDATE SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d7eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make quick changes to config.toml\n",
    "def change_toml(edits, configfile):\n",
    "    # read config\n",
    "    myconfig = toml.load(configfile)\n",
    "    # change config\n",
    "    for key, value in edits.items():\n",
    "        myconfig[key] = value\n",
    "    # dump config\n",
    "    with open(configfile, 'w') as f:\n",
    "        new_toml_string = toml.dump(myconfig, f)\n",
    "    print(new_toml_string)\n",
    "\n",
    "# check video extension by content\n",
    "def check_videotype(projectpath, dir):\n",
    "    session = os.listdir(projectpath)[0]\n",
    "    path = os.path.join(projectpath, session, dir)  \n",
    "    videotype = os.listdir(path)[0].split('.')[-1]\n",
    "    return videotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7876e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit project specific anipose configurations\n",
    "edits = {\n",
    "    'project': projectpath, \n",
    "    'model_folder': 'C:/Users/myore/Desktop/MYOREHAB/vecinita/test_2d-vecinita-2025-05-16/dlc-models-pytorch/iteration-0/test_2dMay16-trainset95shuffle1/train',             # change path to deeplabcut project here\n",
    "    'nesting': 1, \n",
    "    'video_extension': 'mp4',       # change video type here\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'pose_2d': 'pose-2d',\n",
    "        'calibration_videos': 'calibration',\n",
    "    },\n",
    "    'calibration': {                # change calibration settings here\n",
    "        'board_type': 'charuco', \n",
    "        'board_size': [10, 7], \n",
    "        'board_marker_bits': 4, \n",
    "        'board_marker_dict_number': 50, \n",
    "        'board_marker_length': 2.00, \n",
    "        'board_square_side_length': 2.70, \n",
    "        'animal_calibration': False, \n",
    "        'fisheye': False,\n",
    "        }, \n",
    "    'manual_verification': {\n",
    "        'manually_verify': False,\n",
    "        },\n",
    "    'labeling': {                   # change labeling settings here\n",
    "        'scheme': [\n",
    "            ['Wrist', 'Thumb0', 'Thumb1', 'Thumb2', 'Thumb3'],\n",
    "            ['Wrist', 'Index0', 'Index1', 'Index2', 'Index3'],\n",
    "            ['Wrist', 'Middle0', 'Middle1', 'Middle2', 'Middle3'],\n",
    "            ['Wrist', 'Ring0', 'Ring1', 'Ring2', 'Ring3'],\n",
    "            ['Wrist', 'Pinkie0', 'Pinkie1', 'Pinkie2', 'Pinkie3'] ]\n",
    "            }, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6a4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_extension = \"mp4\"\n",
      "converted_video_speed = 1\n",
      "project = \"C:/Users/myore/Desktop/MYOREHAB\\\\HandTracking\"\n",
      "model_folder = \"C:/Users/myore/Desktop/MYOREHAB/vecinita/test_2d-vecinita-2025-05-16/dlc-models-pytorch/iteration-0/test_2dMay16-trainset95shuffle1/train\"\n",
      "nesting = 1\n",
      "\n",
      "[calibration]\n",
      "board_type = \"charuco\"\n",
      "board_size = [ 10, 7,]\n",
      "board_marker_bits = 4\n",
      "board_marker_dict_number = 50\n",
      "board_marker_length = 2.0\n",
      "board_square_side_length = 2.7\n",
      "animal_calibration = false\n",
      "fisheye = false\n",
      "\n",
      "[manual_verification]\n",
      "manually_verify = false\n",
      "\n",
      "[triangulation]\n",
      "ransac = false\n",
      "optim = false\n",
      "scale_smooth = 2\n",
      "scale_length = 2\n",
      "scale_length_weak = 1\n",
      "reproj_error_threshold = 5\n",
      "score_threshold = 0.8\n",
      "n_deriv_smooth = 3\n",
      "constraints = []\n",
      "constraints_weak = []\n",
      "\n",
      "[pipeline]\n",
      "videos_raw = \"videos-raw\"\n",
      "pose_2d = \"pose-2d\"\n",
      "calibration_videos = \"calibration\"\n",
      "\n",
      "[filter]\n",
      "enabled = false\n",
      "type = \"medfilt\"\n",
      "medfilt = 13\n",
      "offset_threshold = 25\n",
      "score_threshold = 0.05\n",
      "spline = true\n",
      "n_back = 5\n",
      "multiprocessing = false\n",
      "\n",
      "[filter3d]\n",
      "enabled = false\n",
      "\n",
      "[labeling]\n",
      "scheme = [ [ \"Wrist\", \"Thumb0\", \"Thumb1\", \"Thumb2\", \"Thumb3\",], [ \"Wrist\", \"Index0\", \"Index1\", \"Index2\", \"Index3\",], [ \"Wrist\", \"Middle0\", \"Middle1\", \"Middle2\", \"Middle3\",], [ \"Wrist\", \"Ring0\", \"Ring1\", \"Ring2\", \"Ring3\",], [ \"Wrist\", \"Pinkie0\", \"Pinkie1\", \"Pinkie2\", \"Pinkie3\",],]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "change_toml(edits, configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e8e78",
   "metadata": {},
   "source": [
    "CHECK CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0995e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b881054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DLC_resnet50_test_2dMay16shuffle2_100000'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf(\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/pose-2d-filtered/camA.h5\")\n",
    "print(df.columns.levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca00693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Index0', 'Index1', 'Index2', 'Index3', 'Middle0', 'Middle1', 'Middle2', 'Middle3', 'Pinkie0', 'Pinkie1', 'Pinkie2', 'Pinkie3', 'Ring0', 'Ring1', 'Ring2', 'Ring3', 'Thumb0', 'Thumb1', 'Thumb2', 'Thumb3', 'Wrist']\n"
     ]
    }
   ],
   "source": [
    "bodyparts_in_csv = df.columns.levels[1]\n",
    "print(list(bodyparts_in_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be129ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Wrist', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Wrist', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Wrist', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb0', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb0', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb0', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb1', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb1', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb1', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb2', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb2', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb2', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb3', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb3', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Thumb3', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index0', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index0', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index0', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index1', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index1', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index1', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index2', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index2', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index2', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index3', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index3', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Index3', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle0', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle0', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle0', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle1', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle1', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle1', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle2', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle2', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle2', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle3', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle3', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Middle3', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring0', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring0', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring0', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring1', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring1', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring1', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring2', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring2', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring2', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring3', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring3', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Ring3', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie0', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie0', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie0', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie1', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie1', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie1', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie2', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie2', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie2', 'likelihood')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie3', 'x')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie3', 'y')\n",
      "('DLC_resnet50_test_2dMay16shuffle2_100000', 'Pinkie3', 'likelihood')\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c077701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Renamed 'Thump*' to 'Thumb*' and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the h5 file\n",
    "h5_path = r\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/pose-2d-filtered/camE.h5\"\n",
    "df = pd.read_hdf(h5_path)\n",
    "\n",
    "# Rename all columns that start with \"Thump\" to \"Thumb\"\n",
    "df.columns = pd.MultiIndex.from_tuples([\n",
    "    (scorer, col.replace(\"Thump\", \"Thumb\"), coord)\n",
    "    if \"Thump\" in col else (scorer, col, coord)\n",
    "    for scorer, col, coord in df.columns\n",
    "])\n",
    "\n",
    "# Save back to h5\n",
    "df.to_hdf(h5_path, key='df')\n",
    "print(\"✅ Renamed 'Thump*' to 'Thumb*' and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cada2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in this .h5 file:\n",
      "['/df']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.pytables import HDFStore\n",
    "\n",
    "h5_path = r\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/pose-2d-filtered/camE.h5\"\n",
    "\n",
    "with HDFStore(h5_path) as store:\n",
    "    print(\"Available keys in this .h5 file:\")\n",
    "    print(store.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a433f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned .h5 file — only 'df' key remains.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your h5 file\n",
    "h5_path = r\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/pose-2d-filtered/camE.h5\"\n",
    "\n",
    "# Load the correct dataset\n",
    "df = pd.read_hdf(h5_path, key='df')\n",
    "\n",
    "# Overwrite the file with only 'df' as the key\n",
    "df.to_hdf(h5_path, key='df', mode='w')\n",
    "\n",
    "print(\"✅ Cleaned .h5 file — only 'df' key remains.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0e5270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Frame 1 saved as C:/Users/myore/Desktop/MYOREHAB/extracted_frame.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to your video\n",
    "video_path = r\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camA.mp4\"\n",
    "\n",
    "# Frame number to extract (e.g., 100th frame)\n",
    "frame_number = 1\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Error: Could not open video.\")\n",
    "else:\n",
    "    # Set the frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Save the frame as an image\n",
    "        output_path = \"C:/Users/myore/Desktop/MYOREHAB/extracted_frame.jpg\"\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(f\"✅ Frame {frame_number} saved as {output_path}\")\n",
    "    else:\n",
    "        print(f\"❌ Error: Could not read frame {frame_number}\")\n",
    "\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6681255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (540, 720, 3), Dtype: uint8, Any NaNs? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"C:/Users/myore/Desktop/MYOREHAB/extracted_frame.jpg\")\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(f\"Shape: {img.shape}, Dtype: {img.dtype}, Any NaNs? {np.isnan(img).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41275c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame shape: (540, 720, 3)\n",
      "Frame dtype: uint8\n",
      "Frame min/max: 7 255\n",
      "Test video written successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "\n",
    "def pad_to_even(img):\n",
    "    h, w = img.shape[:2]\n",
    "    pad_bottom = 0 if h % 2 == 0 else 1\n",
    "    pad_right = 0 if w % 2 == 0 else 1\n",
    "    if pad_bottom or pad_right:\n",
    "        img = cv2.copyMakeBorder(img, 0, pad_bottom, 0, pad_right, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "    return img\n",
    "\n",
    "frame = cv2.imread('C:/Users/myore/Desktop/MYOREHAB/extracted_frame.jpg')\n",
    "if frame is None:\n",
    "    raise RuntimeError(\"Failed to load image\")\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = pad_to_even(frame)\n",
    "print(\"Frame shape:\", frame.shape)\n",
    "print(\"Frame dtype:\", frame.dtype)\n",
    "print(\"Frame min/max:\", frame.min(), frame.max())  # Should be (540, 720, 3)\n",
    "frame = frame.astype(np.uint8)\n",
    "\n",
    "writer = skvideo.io.FFmpegWriter(\n",
    "    \"test_output.mp4\",\n",
    "    inputdict={'-framerate': '60'},\n",
    "    outputdict={\n",
    "        #'-vcodec': 'libx264',\n",
    "        #'-qp': '28',\n",
    "        #'-pix_fmt': 'yuv420p',\n",
    "        # Removed '-vf' line here\n",
    "    }\n",
    ")\n",
    "\n",
    "for _ in range(10):\n",
    "    writer.writeFrame(frame)\n",
    "\n",
    "writer.close()\n",
    "print(\"Test video written successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6781f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV video written successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frame = cv2.imread('C:/Users/myore/Desktop/MYOREHAB/extracted_frame.jpg')\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert RGB back to BGR because OpenCV VideoWriter expects BGR\n",
    "frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # try mp4v for wide support\n",
    "out = cv2.VideoWriter('test_opencv_output.mp4', fourcc, 60, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "for _ in range(10):\n",
    "    out.write(frame_bgr)\n",
    "\n",
    "out.release()\n",
    "print(\"OpenCV video written successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd78644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camA.mp4', 'camB.mp4', 'camC.mp4', 'camD.mp4', 'camE.mp4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('C:/Users/myore/Desktop/MYOREHAB/HandTracking_mediapipe/recording/videos-raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Users/myore/Desktop/MYOREHAB/HandTracking_mediapipe/recording/videos-raw/camA.mp4\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video\")\n",
    "else:\n",
    "    print(f\"Video loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d477163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camA.mp4', 'camB.mp4', 'camC.mp4', 'camD.mp4', 'camE.mp4']\n",
      "videos-raw/camA.mp4\n",
      "Load successfully\n",
      "videos-raw/camB.mp4\n",
      "Load successfully\n",
      "videos-raw/camC.mp4\n",
      "Load successfully\n",
      "videos-raw/camD.mp4\n",
      "Load successfully\n",
      "videos-raw/camE.mp4\n",
      "Load successfully\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('C:/Users/myore/Desktop/MYOREHAB/HandTracking_mediapipe/recording/videos-raw')\n",
    "print(files)\n",
    "for file in files:\n",
    "    VIDEO_FILE = file.replace('.mp4','')\n",
    "    print('videos-raw/'+VIDEO_FILE+'.mp4')\n",
    "    cap = cv2.VideoCapture('C:/Users/myore/Desktop/MYOREHAB/HandTracking_mediapipe/recording/videos-raw/'+VIDEO_FILE+'.mp4')\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print('Error:'+VIDEO_FILE+' not loaded.')\n",
    "    else:\n",
    "        print(\"Load successfully\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd220b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
