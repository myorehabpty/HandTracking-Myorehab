{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc7f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.6...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myore\\anaconda3\\envs\\anipose\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import anipose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4aa2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/test_2d-vecinita-2025-05-16/config.yaml\"\n",
    "video_path = \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1481911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-100000 for model C:/Users/myore/Desktop/MYOREHAB/HandTracking/test_2d-vecinita-2025-05-16\\dlc-models\\iteration-0\\test_2dMay16-trainset95shuffle2\n",
      "Starting to analyze %  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4\n",
      "Loading  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4\n",
      "Duration of video [s]:  33.57 , recorded with  60.0 fps!\n",
      "Overall # of frames:  2014  found with (before cropping) frame dimensions:  720 540\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [09:31<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\\session1\\videos-raw...\n",
      "Starting to analyze %  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera2_raw.mp4\n",
      "Loading  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera2_raw.mp4\n",
      "Duration of video [s]:  33.57 , recorded with  60.0 fps!\n",
      "Overall # of frames:  2014  found with (before cropping) frame dimensions:  720 540\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [09:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\\session1\\videos-raw...\n",
      "Starting to analyze %  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera3_raw.mp4\n",
      "Loading  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera3_raw.mp4\n",
      "Duration of video [s]:  33.57 , recorded with  60.0 fps!\n",
      "Overall # of frames:  2014  found with (before cropping) frame dimensions:  720 540\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [09:30<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\\session1\\videos-raw...\n",
      "Starting to analyze %  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera4_raw.mp4\n",
      "Loading  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera4_raw.mp4\n",
      "Duration of video [s]:  33.57 , recorded with  60.0 fps!\n",
      "Overall # of frames:  2014  found with (before cropping) frame dimensions:  720 540\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [09:25<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\\session1\\videos-raw...\n",
      "Starting to analyze %  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera5_raw.mp4\n",
      "Loading  C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera5_raw.mp4\n",
      "Duration of video [s]:  33.55 , recorded with  60.0 fps!\n",
      "Overall # of frames:  2013  found with (before cropping) frame dimensions:  720 540\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2013/2013 [09:20<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\myore\\Desktop\\MYOREHAB\\HandTracking\\session1\\videos-raw...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_test_2dMay16shuffle2_100000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, [\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4\", \n",
    "                                        \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera2_raw.mp4\", \n",
    "                                        \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera3_raw.mp4\", \n",
    "                                        \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera4_raw.mp4\", \n",
    "                                        \"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera5_raw.mp4\"],\n",
    "                          shuffle=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874fc013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4\n",
      "Loading C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/videos-raw/camera1_raw.mp4 and data.\n",
      "Duration of video [s]: 33.57, recorded with 60.0 fps!\n",
      "Overall # of frames: 2014 with cropped frame dimensions: 720 540\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [00:11<00:00, 176.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path, [video_path], shuffle=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fd91a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  894  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "Nothing extracted, please change the parameters and start again...\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames(config_path, [video_path], shuffle=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708432b",
   "metadata": {},
   "source": [
    "OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d23647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c4d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f883398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit.\n",
      "Failed to grab frame.\n"
     ]
    }
   ],
   "source": [
    "charuco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "\n",
    "squares_x = 10  # number of squares along the X axis (columns)\n",
    "squares_y = 7   # number of squares along the Y axis (rows)\n",
    "square_length = 27  # full square size (e.g., cm or mm)\n",
    "marker_length = 20  # ArUco marker size inside the square\n",
    "\n",
    "board = cv2.aruco.CharucoBoard(\n",
    "    (squares_x, squares_y), square_length, marker_length, charuco_dict\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Users/myore/Desktop/MYOREHAB/HandTracking/session1/calibration/calib-charuco-camA.mp4\")  # Change to 1 or 2 if you have multiple webcams\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ArUco markers\n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(gray, charuco_dict)\n",
    "\n",
    "    # If markers are detected, try to interpolate ChArUco corners\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(\n",
    "            markerCorners=corners,\n",
    "            markerIds=ids,\n",
    "            image=gray,\n",
    "            board=board\n",
    "        )\n",
    "\n",
    "        if retval > 0:\n",
    "            cv2.aruco.drawDetectedCornersCharuco(frame, charuco_corners, charuco_ids)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"ChArUco Board Detection\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anipose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
